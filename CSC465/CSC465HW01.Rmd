---
title: "CSC465HW01"
author: "Kaiyuan Hu"
date: "2017/2/12"
output: pdf_document
header-includes:
- \usepackage{amsmath}
---

# Question 1

## a)
Adding a constant *c* in each response *Y* means we can rewite the original model as $Y+C = \beta_0  + \beta_1 X+C$, which is $Y+C = (\beta_0 + C) + \beta_1 X$. So, the new $\beta_1$ is equal to the previous one and th new $\beta_0$ is equal to the original $\beta_0 + c$.


## b)
For the new model: 
$$ \hat Y + C = \hat \beta_0^{'} + \hat \beta_1^{'} X_{new}$$
$$\hat Y = \hat \beta_0^{'} + \hat \beta_1{'} X_{new} - C$$
$$ \hat \beta_1{'} X_{new} - C = \hat \beta_1 X$$
$$ \hat \beta_1{'} X_{new}  = \hat \beta_1 X + C$$
$$ X_{new} = (\hat \beta_1 X + C)/ \hat \beta_1{'}$$
-----------------------------------------------------------------------------------------------

# Question 2

## a)
$$trace(AB^T) = \sum_{i = 1}^{n}\sum_{j =1}^{m}a_{ij}b_{ji} = \sum_{j =1}^{m}\sum_{i = 1}^{n}b_{ji}a_{ij} = trace(B^T A)$$
Then:
$$trace(H) = trace(X(X^T X)^{-1}X^T) = trace(X^T X(X^T X)^{-1}) = trace(I_{q*q}) = q$$

## b) 

### I)
$$H*H = X(X^T X)^{-1}X^T * X(X^T X)^{-1}X^T = X(X^T X)^{-1}X^T X(X^T X)^{-1}X^T = X(X^TX)^{-1}*I*X^T = H $$
So matrix $H$ is idempotent.

### II)
We assume $H \neq HH$, which means there exist $n$ such that $H^n y$ is the closet point in $S_q$ closet to $y$. This statement is contradict to the fact that $Hy$ is the closet point in $S_q$ closet to $y$. So, $H = HH$. 

## c)

### I)
$$\mathbf{H^{'}} = \left[\begin{array}
{rrr}
1/n & \cdots & 1/n \\
\cdots & \cdots & \cdots \\
1/n & \cdots & 1/n
\end{array}\right]_{n*n}$$
$trace(H^{'}) = 1$

### II)
$$\mathbf{H^{'}} = \left[\begin{array}
{rrrrrr}
1/2 & 1/2 & 0 & 0 & 0 & \cdots \\
1/3 & 1/3 & 1/3 & 0 & 0 & \cdots \\
0 & 1/3 & 1/3 & 1/3 & 0 & \cdots \\
\cdots & \cdots & \cdots & \cdots & \cdots & \cdots\\
0 & 0 & \cdots & 1/3 & 1/3 & 1/3 \\
0 & 0 & 0 & \cdots & 1/2 & 1/2
\end{array}\right]$$
$trace(H^{'}) = 1 + (n-2)/3$

### III)
$$\mathbf{H^{'}} = \left[\begin{array}
{rrrr}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\cdots & \cdots & \cdots & \cdots\\
0 & \cdots & 0 & 1
\end{array}\right]_{n*n}$$
$trace(H^{'}) = n$

## d)
When $n = 2$, the order of complexity is $I = II < III$
When $n > 2$, the order of complexity is $I < II < III$

The degree of freedom of $I$ is 1, so the model complexity is low. For model $II$, as the complexity increase the $MSE$ will decrease. For model $III$, the $MSE$ is zero, this model is really complexity. 

----------------------------------------------------------------------------------------------

# Question 3

```{r}
library(MASS)
```

## a)

```{r}
modela = lm(bwt~age, data = birthwt)
```

## b) 

```{r}
inf_measure = influence.measures(modela)
```

## c)

### I&II&III&IV&V)
```{r}
plot(birthwt$bwt~birthwt$age, pch = 20, xlab = 'age', ylab = 'bwt') # I
abline(modela, col = 'red') # II
flag = inf_measure$infmat
points(birthwt$age, birthwt$bwt, col = ifelse(flag[,6] > 4/dim(birthwt)[1], 'red', 'black'), pch = 20) # III
```

```{r}
plot(birthwt$bwt~birthwt$age, pch = 20, xlab = 'age', ylab = 'bwt') # I
abline(modela, col = 'red')
points(birthwt$age[inf_measure$is.inf[,'dffit'] & inf_measure$infmat[,'dffit'] < 0], birthwt$bwt[inf_measure$is.inf[,'dffit'] & inf_measure$infmat[,'dffit'] < 0], type = 'p', col = 'blue', pch = 2)
points(birthwt$age[inf_measure$is.inf[,'dffit'] & inf_measure$infmat[,'dffit'] >= 0], birthwt$bwt[inf_measure$is.inf[,'dffit'] & inf_measure$infmat[,'dffit'] >= 0], type = 'p', col = 'green', pch = 2)
```

```{r}
plot(birthwt$bwt~birthwt$age, pch = 20, xlab = 'age', ylab = 'bwt') # I
abline(modela, col = 'red')# IV
points(birthwt$age[inf_measure$is.inf[,'cov.r'] & inf_measure$infmat[,'cov.r'] < 1], birthwt$bwt[inf_measure$is.inf[,'cov.r'] & inf_measure$infmat[,'cov.r'] < 1], type = 'p', col = 'blue', pch = 6)
points(birthwt$age[inf_measure$is.inf[,'cov.r'] & inf_measure$infmat[,'cov.r'] >= 1], birthwt$bwt[inf_measure$is.inf[,'cov.r'] & inf_measure$infmat[,'cov.r'] >= 1], type = 'p', col = 'green', pch = 6) #V
```

## d)
It seems the fitted line distinguishes high and low *DFFITSi*. High *DFFITSi* value usually above the fitted line and low *DFFITSi* value usually below the fitted line. 

## e)
No. As we can see in the figure, no flag criterion is dominates. We need them all to detect outliers.

## f)
As we can see in the figure, If the bwt value is higher than 4000 or lower than 2000 or age large than 35, observations will have high covariance ratio.

If a value is too far away from most other values, remove this point, the standard error of $\beta$ will decrease. 

## g)
$X_{,,}$ yield lower varience, since $(X_{,,}^TX_{,,})^{-1} < (X_{,}^TX_{,})^{-1}$.

## h)
The large sample variance will cause small beta varience. 

## i)
No. Coveriance ratio it alone can not tell which point is really a outlier, since coveriance ratio only compute the distance between points. However, far distance does not necessaily means it is a outlier. 

------------------------------------------------------------------------------------------------

# Question 4

## a)

```{r}
newbirthwt = sub <- subset(birthwt,!inf_measure$is.inf[,'dffit'])
```

## b)

```{r}
summary.table = function(fit){
    Nonsmoke.Intercept = summary(fit)$coef[1,1]
    Nonsmoke.slope = 0
    Smoke.Intercept = summary(fit)$coef[2,1] + Nonsmoke.Intercept
    Smoke.slope = 0
    
    if(i == 1){
      Nonsmoke.slope = summary(fit)$coef[2,1]
      Smoke.Intercept = NA
      Smoke.slope = NA
    }
    
    if(i == 2){
      Smoke.Intercept = Nonsmoke.Intercept + summary(fit)$coef[2,1]
    }
    
    if(i == 3){
      Smoke.Intercept = Smoke.slope = summary(fit)$coef[3,1]
    }
    
    if(i == 4){
      Smoke.slope = summary(fit)$coef[3,1]
    }
    
    if(i == 5){
      Nonsmoke.slope = summary(fit)$coef[3,1]
    }
    
    if(i == 6){
      Nonsmoke.slope = summary(fit)$coef[3,1]
      Smoke.slope = Nonsmoke.slope + summary(fit)$coef[4,1]
    }
    
    Radj = summary(fit)$adj.r.squared
    Numerator.d.f = summary(fit)$f[2]
    Denominator.d.f = summary(fit)$f[3]
    Fstat = summary(fit)$f[1]
    Pv = 1 - pf(Fstat,Numerator.d.f,Denominator.d.f)
  
    sumname = data.frame( Nonsmoke.Intercept, Nonsmoke.slope, Smoke.Intercept, Smoke.slope,
                          Radj, Numerator.d.f, Denominator.d.f, Fstat, Pv)
    sum = c( Nonsmoke.Intercept, Nonsmoke.slope, Smoke.Intercept, Smoke.slope, Radj,
             Numerator.d.f,Denominator.d.f, Fstat, Pv)
  
    names(sum) = names(sumname)
    
    # print(summary(fit))
  return(sum)
}

newbirthwt$nonsmoke <- ifelse(newbirthwt$smoke == 1, 0, 1)
newbirthwt$smoke <- as.numeric(newbirthwt$smoke)
newbirthwt$nonsmoke<- as.numeric(newbirthwt$nonsmoke)
bwt <- newbirthwt$bwt
smoke <- newbirthwt$smoke
nonsmoke <- newbirthwt$nonsmoke
age <- newbirthwt$age

formula.list = list(
  bwt ~ age,
  bwt ~ smoke,
  bwt ~ smoke + age,
  bwt ~ smoke + I(smoke*age),
  bwt ~ smoke + I(nonsmoke*age),
  bwt ~ smoke + age + I(smoke*age)
)

table = NULL
for (i in 1:6)  table = rbind(table, summary.table(lm(formula.list[[i]]))) 
row.names(table) = formula.list 
table
```

## c)
```{r}
par(mfrow=c(3,2))
newbirthwt$smoke <- as.numeric(newbirthwt$smoke)
newbirthwt$nonsmoke <- ifelse(newbirthwt$smoke == 1, 0, 1)
newbirthwt$smoke <- as.numeric(newbirthwt$smoke)
newbirthwt$nonsmoke<- as.numeric(newbirthwt$nonsmoke)
bwt <- newbirthwt$bwt
smoke <- newbirthwt$smoke
nonsmoke <- newbirthwt$nonsmoke
age <- newbirthwt$age

formula.list = list(
  bwt ~ age,
  bwt ~ smoke,
  bwt ~ smoke + age,
  bwt ~ smoke + I(smoke*age),
  bwt ~ smoke + I(nonsmoke*age),
  bwt ~ smoke + age + I(smoke*age)
)
data = list(  
  data.frame(age),
  data.frame(smoke),
  data.frame(smoke, age),
  data.frame(smoke, I(smoke*age)),
  data.frame(smoke, I(nonsmoke*age)),
  data.frame(smoke, age, I(smoke*age))
  )


for(i in 1:6){
  plot(predict(lm(formula.list[[i]]), newdata = data[i])~age, 
       ylab = "bwt", xlab = "age",main= formula.list[[i]])}
```

## d)

The model *bwt ~ smoke + I(nonsmoke \* age)* has the highest $R^2_{adj}$ value, which is 0.023..

```{r}
summary(lm(bwt ~ smoke + I(nonsmoke * age)))
```
For nonsmoker the model is $Y = 2624.25 + 7.84 * X$.
For smoker the model is $Y = 2823.30 + 0 * X$.

## e)

Model 2 is the submodel of model5 has the largest number of model degree of freedom. 

```{r}
M2 = lm(bwt ~ smoke)
M5 = lm(bwt ~ smoke + I(nonsmoke * age))
anova(M2,M5)
```
As we can the p-value in the anvoa, the result seems not yield the same conclusion as the $R^2_{adj}$ ranking. 

